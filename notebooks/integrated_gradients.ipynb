{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3135b687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/1 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Input and baseline must have the same dimensions, baseline has 3 features whereas input has 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m target \u001b[38;5;241m=\u001b[39m (length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, encoded_ids[\u001b[38;5;241m0\u001b[39m, length\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     42\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m encoded_ids[:, :length]\n\u001b[0;32m---> 43\u001b[0m attributions \u001b[38;5;241m=\u001b[39m \u001b[43mIG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m sum_attr \u001b[38;5;241m=\u001b[39m sum_embedding_attributions(attributions)\n\u001b[1;32m     49\u001b[0m attributions_list\u001b[38;5;241m.\u001b[39mappend(sum_attr)\n",
      "File \u001b[0;32m~/.conda/envs/rome/lib/python3.9/site-packages/captum/log/__init__.py:35\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rome/lib/python3.9/site-packages/captum/attr/_core/layer/layer_integrated_gradients.py:488\u001b[0m, in \u001b[0;36mLayerIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mig\u001b[38;5;241m.\u001b[39mgradient_func \u001b[38;5;241m=\u001b[39m gradient_func\n\u001b[1;32m    482\u001b[0m all_inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    483\u001b[0m     (inps \u001b[38;5;241m+\u001b[39m additional_forward_args)\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m additional_forward_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m inps\n\u001b[1;32m    486\u001b[0m )\n\u001b[0;32m--> 488\u001b[0m attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# self\u001b[39;49;00m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43minternal_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minternal_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# handle multiple outputs\u001b[39;00m\n\u001b[1;32m    501\u001b[0m output: List[Tuple[Tensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    503\u001b[0m         attributions[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(num_outputs))\n\u001b[1;32m    508\u001b[0m ]\n",
      "File \u001b[0;32m~/.conda/envs/rome/lib/python3.9/site-packages/captum/attr/_core/integrated_gradients.py:269\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    265\u001b[0m is_inputs_tuple \u001b[38;5;241m=\u001b[39m _is_tuple(inputs)\n\u001b[1;32m    267\u001b[0m inputs, baselines \u001b[38;5;241m=\u001b[39m _format_input_baseline(inputs, baselines)\n\u001b[0;32m--> 269\u001b[0m \u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m     num_examples \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/rome/lib/python3.9/site-packages/captum/attr/_utils/common.py:45\u001b[0m, in \u001b[0;36m_validate_input\u001b[0;34m(inputs, baselines, n_steps, method, draw_baseline_from_distrib)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_input\u001b[39m(\n\u001b[1;32m     39\u001b[0m     inputs: Tuple[Tensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m     40\u001b[0m     baselines: Tuple[Union[Tensor, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     draw_baseline_from_distrib: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[43m_validate_input_basic\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraw_baseline_from_distrib\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m         n_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     48\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of steps must be a positive integer. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     51\u001b[0m         method \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_METHODS\n\u001b[1;32m     52\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApproximation method must be one for the following \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     53\u001b[0m         SUPPORTED_METHODS, method\n\u001b[1;32m     54\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/rome/lib/python3.9/site-packages/captum/_utils/common.py:78\u001b[0m, in \u001b[0;36m_validate_input\u001b[0;34m(inputs, baselines, draw_baseline_from_distrib)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_input\u001b[39m(\n\u001b[1;32m     74\u001b[0m     inputs: Tuple[Tensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m     75\u001b[0m     baselines: Tuple[Union[Tensor, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m     76\u001b[0m     draw_baseline_from_distrib: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     77\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(baselines), (\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput and baseline must have the same \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimensions, baseline has \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m features whereas input has \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;28mlen\u001b[39m(baselines), \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[1;32m     82\u001b[0m         )\n\u001b[1;32m     83\u001b[0m     )\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, baseline \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs, baselines):\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m draw_baseline_from_distrib:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Input and baseline must have the same dimensions, baseline has 3 features whereas input has 2."
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients, LayerIntegratedGradients\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-xl', pad_token_id=tokenizer.eos_token_id)\n",
    "start_text = \"Megan Rapinoe plays the sport of\"\n",
    "start_text = \"The Big Bang Theory premieres on\"\n",
    "\n",
    "encoded_input = tokenizer(start_text, return_tensors='pt')\n",
    "start_length = encoded_input.input_ids.shape[-1]\n",
    "\n",
    "generated_text_length = 1\n",
    "max_length = start_length + generated_text_length\n",
    "\n",
    "generate = model.generate(**encoded_input, max_length=max_length)\n",
    "\n",
    "encoded_ids = generate\n",
    "\n",
    "attributions_list = list()\n",
    "\n",
    "def untuple(x):\n",
    "    if isinstance(x, tuple):\n",
    "        return x[0]\n",
    "    return x\n",
    "    \n",
    "def model_forward_wrapper(*args, **kwargs):\n",
    "    output = model(args[0].long(), **kwargs, return_dict=False)[0]\n",
    "    return output\n",
    "\n",
    "#IG = LayerIntegratedGradients(model_forward_wrapper, model.transformer.wte)\n",
    "IG = LayerIntegratedGradients(model_forward_wrapper, model.transformer.h[15])\n",
    "\n",
    "def sum_embedding_attributions(attributions):\n",
    "    return torch.sum(untuple(attributions) ** 2, dim=-1).sqrt().squeeze()\n",
    "\n",
    "for i in tqdm(range(0, generated_text_length)):\n",
    "    length = start_length + i\n",
    "    baseline = torch.tensor([[tokenizer.unk_token_id] * length]).long()\n",
    "    target = (length - 1, encoded_ids[0, length-1].item())\n",
    "    input_ids = encoded_ids[:, :length]\n",
    "    attributions = IG.attribute(\n",
    "        inputs = input_ids,\n",
    "        baselines = baseline,\n",
    "        target = target\n",
    "    )\n",
    "    sum_attr = sum_embedding_attributions(attributions)\n",
    "    attributions_list.append(sum_attr)\n",
    "\n",
    "for attribution in attributions_list:\n",
    "    print(attribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.bar([tokenizer.decode(tok) for tok in input_ids[0]], attribution)\n",
    "for tok, att in zip(input_ids[0], attribution):\n",
    "    print(tokenizer.decode(tok), att.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_attributions = {}\n",
    "\n",
    "for kind in ['', 'mlp', 'attn']:\n",
    "    layer_attributions[kind] = []\n",
    "    for layernum in tqdm(range(0, 48)):\n",
    "        IG = LayerIntegratedGradients(model_forward_wrapper,\n",
    "                    model.transformer.h[layernum] if not kind\n",
    "                    else model.transformer.h[layernum].mlp if kind == 'mlp'\n",
    "                    else model.transformer.h[layernum].mlp.c_fc if kind == 'mlp_fc'\n",
    "                    else model.transformer.h[layernum].attn)\n",
    "\n",
    "        length = start_length\n",
    "        baseline = torch.tensor([[tokenizer.unk_token_id] * length]).long()\n",
    "        target = (length - 1, encoded_ids[0, length-1].item())\n",
    "        input_ids = encoded_ids[:, :length]\n",
    "        attributions = IG.attribute(\n",
    "            inputs = input_ids,\n",
    "            baselines = baseline,\n",
    "            target = target\n",
    "        )\n",
    "        sum_attr = sum_embedding_attributions(attributions)\n",
    "        layer_attributions[kind].append(sum_attr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a7836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trace_heatmap(result, savepdf=None, title=None, xlabel=None):\n",
    "    differences = result[\"scores\"]\n",
    "    low_score = result[\"low_score\"]\n",
    "    kind = (\n",
    "        None\n",
    "        if (not result[\"kind\"] or result[\"kind\"] == \"None\")\n",
    "        else str(result[\"kind\"])\n",
    "    )\n",
    "    labels = list(result[\"input_tokens\"])\n",
    "    for i in range(*result[\"subject_range\"]):\n",
    "        labels[i] = labels[i] + \"*\"\n",
    "\n",
    "    with plt.rc_context(rc={\"font.family\": \"Times New Roman\"}):\n",
    "        fig, ax = plt.subplots(figsize=(3.5, 2), dpi=200)\n",
    "        h = ax.pcolor(\n",
    "            differences,\n",
    "            cmap={None: \"Purples\", \"None\": \"Purples\", \"mlp\": \"Greens\", \"mlp_fc\": \"Blues\", \"attn\": \"Reds\"}[\n",
    "                kind\n",
    "            ],\n",
    "            vmin=low_score,\n",
    "        )\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_yticks([0.5 + i for i in range(len(differences))])\n",
    "        ax.set_xticks([0.5 + i for i in range(0, differences.shape[1] - 6, 5)])\n",
    "        ax.set_xticklabels(list(range(0, differences.shape[1] - 6, 5)))\n",
    "        ax.set_yticklabels(labels)\n",
    "        if not kind:\n",
    "            ax.set_title(\"Layer integrated gradient for hidden state\")\n",
    "            ax.set_xlabel(\"single layer within GPT-2-XL\")\n",
    "        else:\n",
    "            kindname = \"MLP\" if kind == \"mlp\" else \"MLP FC\" if kind == \"mlp_fc\" else \"Attn\"\n",
    "            ax.set_title(f\"Layer integrated gradient on {kindname} output\")\n",
    "            ax.set_xlabel(\"single layer within GPT-2-XL\")\n",
    "        cb = plt.colorbar(h)\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "        if xlabel is not None:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        cb.ax.set_title(f\"||IG||\", y=-0.16, fontsize=10)\n",
    "        if savepdf:\n",
    "            os.makedirs(os.path.dirname(savepdf), exist_ok=True)\n",
    "            plt.savefig(savepdf, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "for kind in ['', 'mlp', 'attn']: # ['mlp_fc']: #, \n",
    "    plot_trace_heatmap(dict(\n",
    "        scores=torch.stack(layer_attributions[kind]).t(),\n",
    "        low_score=0,\n",
    "        answer='soccer',\n",
    "        kind=kind,\n",
    "        input_tokens=[tokenizer.decode(tok) for tok in input_ids[0]],\n",
    "        subject_range=[0,0],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.h[layernum].mlp.c_fc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
