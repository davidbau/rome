{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3135b687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0066, 0.7797, 0.3535, 1.0482, 2.1767, 0.1241, 1.7731],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients, LayerIntegratedGradients\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-xl', pad_token_id=tokenizer.eos_token_id)\n",
    "start_text = \"Megan Rapinoe plays the sport of\"\n",
    "start_text = \"The Big Bang Theory premieres on\"\n",
    "\n",
    "\n",
    "n_steps=50\n",
    "\n",
    "\n",
    "encoded_input = tokenizer(start_text, return_tensors='pt')\n",
    "start_length = encoded_input.input_ids.shape[-1]\n",
    "\n",
    "generated_text_length = 1\n",
    "max_length = start_length + generated_text_length\n",
    "\n",
    "generate = model.generate(**encoded_input, max_length=max_length)\n",
    "\n",
    "encoded_ids = generate\n",
    "\n",
    "attributions_list = list()\n",
    "\n",
    "def untuple(x):\n",
    "    if isinstance(x, tuple):\n",
    "        return x[0]\n",
    "    return x\n",
    "    \n",
    "def model_forward_wrapper(*args, **kwargs):\n",
    "    output = model(args[0].long(), **kwargs, return_dict=False)[0]\n",
    "    return output\n",
    "\n",
    "#IG = LayerIntegratedGradients(model_forward_wrapper, model.transformer.wte)\n",
    "IG = LayerIntegratedGradients(model_forward_wrapper, model.transformer.h[15])\n",
    "\n",
    "def sum_embedding_attributions(attributions):\n",
    "    return torch.sum(untuple(attributions) ** 2, dim=-1).sqrt().squeeze()\n",
    "\n",
    "for i in tqdm(range(0, generated_text_length)):\n",
    "    length = start_length + i\n",
    "    baseline = torch.tensor([[tokenizer.unk_token_id] * length]).long()\n",
    "    target = (length - 1, encoded_ids[0, length-1].item())\n",
    "    input_ids = encoded_ids[:, :length]\n",
    "    attributions = IG.attribute(\n",
    "        inputs = input_ids,\n",
    "        baselines = baseline,\n",
    "        target = target,\n",
    "        n_steps = n_steps,\n",
    "    )\n",
    "    sum_attr = sum_embedding_attributions(attributions)\n",
    "    attributions_list.append(sum_attr)\n",
    "\n",
    "for attribution in attributions_list:\n",
    "    print(attribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24f670a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0.006593019076484501\n",
      " Big 0.7797055834515826\n",
      " Bang 0.3534897389031462\n",
      " Theory 1.0481636722259184\n",
      " premie 2.1766928142137103\n",
      "res 0.12409425609007092\n",
      " on 1.773079311367257\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.bar([tokenizer.decode(tok) for tok in input_ids[0]], attribution)\n",
    "for tok, att in zip(input_ids[0], attribution):\n",
    "    print(tokenizer.decode(tok), att.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee85ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    layer_attributions = {}\n",
    "\n",
    "    for kind in ['', 'mlp', 'attn']:\n",
    "        layer_attributions[kind] = []\n",
    "        for layernum in tqdm(range(0, 48)):\n",
    "            IG = LayerIntegratedGradients(model_forward_wrapper,\n",
    "                        model.transformer.h[layernum] if not kind\n",
    "                        else model.transformer.h[layernum].mlp if kind == 'mlp'\n",
    "                        else model.transformer.h[layernum].mlp.c_fc if kind == 'mlp_fc'\n",
    "                        else model.transformer.h[layernum].attn)\n",
    "\n",
    "            length = start_length\n",
    "            baseline = torch.tensor([[tokenizer.unk_token_id] * length]).long()\n",
    "            target = (length - 1, encoded_ids[0, length-1].item())\n",
    "            input_ids = encoded_ids[:, :length]\n",
    "            attributions = IG.attribute(\n",
    "                inputs = input_ids,\n",
    "                baselines = baseline,\n",
    "                target = target,\n",
    "                n_steps = n_steps,\n",
    "            )\n",
    "            sum_attr = sum_embedding_attributions(attributions)\n",
    "            layer_attributions[kind].append(sum_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e78a7836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trace_heatmap(result, savepdf=None, title=None, xlabel=None):\n",
    "    differences = result[\"scores\"]\n",
    "    low_score = result[\"low_score\"]\n",
    "    kind = (\n",
    "        None\n",
    "        if (not result[\"kind\"] or result[\"kind\"] == \"None\")\n",
    "        else str(result[\"kind\"])\n",
    "    )\n",
    "    labels = list(result[\"input_tokens\"])\n",
    "    for i in range(*result[\"subject_range\"]):\n",
    "        labels[i] = labels[i] + \"*\"\n",
    "\n",
    "    with plt.rc_context(rc={\"font.family\": \"Times New Roman\"}):\n",
    "        fig, ax = plt.subplots(figsize=(3.5, 2), dpi=200)\n",
    "        h = ax.pcolor(\n",
    "            differences,\n",
    "            cmap={None: \"Purples\", \"None\": \"Purples\", \"mlp\": \"Greens\", \"mlp_fc\": \"Blues\", \"attn\": \"Reds\"}[\n",
    "                kind\n",
    "            ],\n",
    "            vmin=low_score,\n",
    "            vmax=min(2.0, (differences).max())\n",
    "        )\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_yticks([0.5 + i for i in range(len(differences))])\n",
    "        ax.set_xticks([0.5 + i for i in range(0, differences.shape[1] - 6, 5)])\n",
    "        ax.set_xticklabels(list(range(0, differences.shape[1] - 6, 5)))\n",
    "        ax.set_yticklabels(labels)\n",
    "        if not kind:\n",
    "            ax.set_title(\"Layer integrated gradient for hidden state\")\n",
    "            ax.set_xlabel(\"single layer within GPT-2-XL\")\n",
    "        else:\n",
    "            kindname = \"MLP\" if kind == \"mlp\" else \"MLP FC\" if kind == \"mlp_fc\" else \"Attn\"\n",
    "            ax.set_title(f\"Layer integrated gradient on {kindname} output\")\n",
    "            ax.set_xlabel(\"single layer within GPT-2-XL\")\n",
    "        cb = plt.colorbar(h)\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "        if xlabel is not None:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        cb.ax.set_title(f\"||IG||\", y=-0.16, fontsize=10)\n",
    "        if savepdf:\n",
    "            os.makedirs(os.path.dirname(savepdf), exist_ok=True)\n",
    "            plt.savefig(savepdf, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "if False:\n",
    "    for kind in ['', 'mlp', 'attn']: # ['mlp_fc']: #, \n",
    "        plot_trace_heatmap(dict(\n",
    "            scores=torch.stack(layer_attributions[kind]).t(),\n",
    "            low_score=0,\n",
    "            kind=kind,\n",
    "            input_tokens=[tokenizer.decode(tok) for tok in input_ids[0]],\n",
    "            subject_range=[0,0],\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b837ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_ig_for(start_text):\n",
    "\n",
    "    n_steps=50\n",
    "\n",
    "\n",
    "    encoded_input = tokenizer(start_text, return_tensors='pt')\n",
    "    start_length = encoded_input.input_ids.shape[-1]\n",
    "\n",
    "    generated_text_length = 1\n",
    "    max_length = start_length + generated_text_length\n",
    "\n",
    "    generate = model.generate(**encoded_input, max_length=max_length)\n",
    "\n",
    "    encoded_ids = generate\n",
    "\n",
    "    attributions_list = list()\n",
    "\n",
    "    def untuple(x):\n",
    "        if isinstance(x, tuple):\n",
    "            return x[0]\n",
    "        return x\n",
    "\n",
    "    def model_forward_wrapper(*args, **kwargs):\n",
    "        output = model(args[0].long(), **kwargs, return_dict=False)[0]\n",
    "        return output\n",
    "\n",
    "    #IG = LayerIntegratedGradients(model_forward_wrapper, model.transformer.wte)\n",
    "    IG = LayerIntegratedGradients(model_forward_wrapper, model.transformer.h[15])\n",
    "\n",
    "    def sum_embedding_attributions(attributions):\n",
    "        return torch.sum(untuple(attributions) ** 2, dim=-1).sqrt().squeeze()\n",
    "\n",
    "    layer_attributions = {}\n",
    "\n",
    "    for kind in ['', 'mlp', 'attn']:\n",
    "        layer_attributions[kind] = []\n",
    "        for layernum in tqdm(range(0, 48)):\n",
    "            IG = LayerIntegratedGradients(model_forward_wrapper,\n",
    "                        model.transformer.h[layernum] if not kind\n",
    "                        else model.transformer.h[layernum].mlp if kind == 'mlp'\n",
    "                        else model.transformer.h[layernum].mlp.c_fc if kind == 'mlp_fc'\n",
    "                        else model.transformer.h[layernum].attn)\n",
    "\n",
    "            length = start_length\n",
    "            baseline = torch.tensor([[tokenizer.unk_token_id] * length]).long()\n",
    "            target = (length - 1, encoded_ids[0, length-1].item())\n",
    "            input_ids = encoded_ids[:, :length]\n",
    "            attributions = IG.attribute(\n",
    "                inputs = input_ids,\n",
    "                baselines = baseline,\n",
    "                target = target,\n",
    "                n_steps = n_steps,\n",
    "            )\n",
    "            sum_attr = sum_embedding_attributions(attributions)\n",
    "            layer_attributions[kind].append(sum_attr)\n",
    "        savepdf = f'ig_pdf/{start_text.replace(\" \", \"_\")}_{kind}.pdf'\n",
    "        plot_trace_heatmap(dict(\n",
    "            scores=torch.stack(layer_attributions[kind]).t(),\n",
    "            low_score=0,\n",
    "            kind=kind,\n",
    "            input_tokens=[tokenizer.decode(tok) for tok in input_ids[0]],\n",
    "            subject_range=[0,0],\n",
    "        ), savepdf=savepdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e736a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexus's owner,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 48/48 [02:33<00:00,  3.21s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [02:36<00:00,  3.26s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [02:33<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTFS is developed by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 48/48 [02:57<00:00,  3.71s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [02:59<00:00,  3.74s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [02:58<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lawrence Tayor professionally plays the sport of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 48/48 [03:44<00:00,  4.69s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [03:47<00:00,  4.75s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [03:48<00:00,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows Media Player is developed by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 48/48 [02:56<00:00,  3.68s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [02:53<00:00,  3.61s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [03:02<00:00,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edmund Neupert, performing on theBrian De Palma works in the area of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 48/48 [06:45<00:00,  8.45s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [06:37<00:00,  8.29s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [06:47<00:00,  8.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germaine Greer's domain of work is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 48/48 [04:13<00:00,  5.27s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [04:11<00:00,  5.25s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [04:13<00:00,  5.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The headquarter of Zillow is in downtown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 48/48 [04:13<00:00,  5.27s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [04:12<00:00,  5.27s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [04:12<00:00,  5.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitsubishi Electric started in the early 1900s as a small company in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 48/48 [05:40<00:00,  7.09s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [05:40<00:00,  7.08s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [05:43<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madame de Montesson died in the city of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 48/48 [04:11<00:00,  5.23s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [04:08<00:00,  5.18s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 48/48 [04:15<00:00,  5.32s/it]\n"
     ]
    }
   ],
   "source": [
    "for t in [\n",
    "    'Lexus\\'s owner,',\n",
    "    'NTFS is developed by',\n",
    "    'Lawrence Tayor professionally plays the sport of',\n",
    "    'Windows Media Player is developed by',\n",
    "    'Edmund Neupert, performing on the'\n",
    "    'Brian De Palma works in the area of',\n",
    "    'Germaine Greer\\'s domain of work is',\n",
    "    'The headquarter of Zillow is in downtown',\n",
    "    'Mitsubishi Electric started in the early 1900s as a small company in',\n",
    "    'Madame de Montesson died in the city of',\n",
    "]:\n",
    "    print(t)\n",
    "    run_full_ig_for(t)\n"
   ]
  }
 ],
 "metadata": {
  "git": {
   "keep_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
