{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f91f9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, clip, json\n",
    "from baukit import pbar\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "clip_model, clip_preprocess = clip.load('ViT-B/32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f61c7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/datasets/coco/annotations/captions_train2017.json') as f:\n",
    "    data = json.load(f)\n",
    "    captions = [r['caption'] for r in data['annotations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50d7594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bce3d9ab404415fb6c63cb2eba80dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for caption in pbar(captions[:100000]):\n",
    "    tx = clip.tokenize(caption)\n",
    "    out = clip_model.encode_text(tx.cuda()).cpu()\n",
    "    result.append(out)\n",
    "\n",
    "clip_text_encodings = torch.cat(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61cfbac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy\n",
    "dirname = 'clip_sample'\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "numpy.save(f'{dirname}/clip_text_encoding.npy', clip_text_encodings.numpy())\n",
    "\n",
    "with open(f'{dirname}/clip_text.json', 'w') as f:\n",
    "    json.dump(captions[:100000], f, indent=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "576e9112",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbaukit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelImageFolders\n\u001b[1;32m      3\u001b[0m ds \u001b[38;5;241m=\u001b[39m ParallelImageFolders([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/datasets/coco/images/train2017\u001b[39m\u001b[38;5;124m'\u001b[39m], transform\u001b[38;5;241m=\u001b[39mclip_preprocess)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from baukit import ParallelImageFolders\n",
    "\n",
    "ds = ParallelImageFolders(['/data/datasets/coco/images/train2017'], transform=clip_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b820e39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12677725a26c42efa33eb791639a6b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     image_results\u001b[38;5;241m.\u001b[39mappend(image_encodings\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m      7\u001b[0m clip_image_encodings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(image_results)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mnumpy\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/clip_image_encoding.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, clip_image_encodings\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "loader = torch.utils.data.DataLoader(\n",
    "    ds, batch_size=20, pin_memory=True, num_workers=8)\n",
    "image_results = []\n",
    "for [batch] in pbar(loader):\n",
    "    image_encodings = clip_model.encode_image(batch.cuda())\n",
    "    image_results.append(image_encodings.cpu())\n",
    "clip_image_encodings = torch.cat(image_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab5f4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.save(f'{dirname}/clip_image_encoding.npy', clip_image_encodings.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
